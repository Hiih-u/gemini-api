import os
import time
import uuid
import secrets
import json
from contextlib import asynccontextmanager
from datetime import datetime
from pathlib import Path
from typing import Optional, List

from dotenv import load_dotenv
from fastapi import FastAPI, HTTPException, Request, UploadFile, File
from fastapi.responses import FileResponse, HTMLResponse
from fastapi.staticfiles import StaticFiles
from fastapi.middleware.cors import CORSMiddleware
from gemini_webapi import GeminiClient
from gemini_webapi.constants import Model
from pydantic import BaseModel

load_dotenv()

# é…ç½®
Secure_1PSID = os.getenv("SECURE_1PSID")
Secure_1PSIDTS = os.getenv("SECURE_1PSIDTS")
HOST = os.getenv("HOST", "0.0.0.0")
PORT = int(os.getenv("PORT", 8000))
IMAGES_BASE_DIR = Path(os.getenv("IMAGES_DIR", "stored_images"))
IMAGES_BASE_DIR.mkdir(exist_ok=True)

CONVERSATIONS_DIR = Path("conversations")
CONVERSATIONS_DIR.mkdir(exist_ok=True)

UPLOADS_DIR = Path("uploads")
UPLOADS_DIR.mkdir(exist_ok=True)

STATIC_DIR = Path("static")
STATIC_DIR.mkdir(exist_ok=True)

gemini_client = None
active_chats = {}

DEBUG = os.getenv("DEBUG", "true").lower() == "true"

# ä¾èµ–æ£€æŸ¥
try:
    import multipart
except ImportError:
    print("=" * 60)
    print("âŒ ç¼ºå°‘ä¾èµ–: python-multipart")
    print("ğŸ“¦ è¯·è¿è¡Œ: pip install python-multipart")
    print("=" * 60)
    raise


def debug_log(message: str, level: str = "INFO"):
    """ç»Ÿä¸€çš„ debug æ—¥å¿—è¾“å‡º"""
    if DEBUG:
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        emoji_map = {
            "INFO": "â„¹ï¸", "SUCCESS": "âœ…", "ERROR": "âŒ",
            "WARNING": "âš ï¸", "DEBUG": "ğŸ”", "REQUEST": "ğŸ“",
            "RESPONSE": "ğŸ“¤", "IMAGE": "ğŸ–¼ï¸", "FILE": "ğŸ“", "CHAT": "ğŸ’¬"
        }
        emoji = emoji_map.get(level, "â€¢")
        print(f"[{timestamp}] {emoji} {message}")


@asynccontextmanager
async def lifespan(app: FastAPI):
    global gemini_client
    debug_log("å¼€å§‹åˆå§‹åŒ– Gemini å®¢æˆ·ç«¯...", "INFO")
    try:
        gemini_client = GeminiClient(Secure_1PSID, Secure_1PSIDTS)
        await gemini_client.init(auto_refresh=True)
        debug_log("Gemini å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ", "SUCCESS")
        debug_log(f"å›¾ç‰‡å­˜å‚¨ç›®å½•: {IMAGES_BASE_DIR.absolute()}", "INFO")
        debug_log(f"å¯¹è¯å†å²ç›®å½•: {CONVERSATIONS_DIR.absolute()}", "INFO")
        debug_log(f"ä¸Šä¼ æ–‡ä»¶ç›®å½•: {UPLOADS_DIR.absolute()}", "INFO")
        debug_log(f"é™æ€æ–‡ä»¶ç›®å½•: {STATIC_DIR.absolute()}", "INFO")
    except Exception as e:
        debug_log(f"åˆå§‹åŒ–å¤±è´¥: {e}", "ERROR")
        raise
    yield


app = FastAPI(lifespan=lifespan, title="Gemini Chat API", version="1.0.0")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# æŒ‚è½½é™æ€æ–‡ä»¶ç›®å½•
app.mount("/static", StaticFiles(directory="static"), name="static")


class Message(BaseModel):
    role: str
    content: str


class ChatRequest(BaseModel):
    model: str
    messages: List[Message]
    conversation_id: Optional[str] = None
    files: Optional[List[str]] = None  # æ–‡ä»¶è·¯å¾„åˆ—è¡¨


MODEL_MAP = {
    "gemini-pro": Model.G_2_5_PRO,
    "gemini-2.5-pro": Model.G_2_5_PRO,
    "gemini-2.5-flash": Model.G_2_5_FLASH,
    "gemini-3.0-pro": Model.G_3_0_PRO,
    "default": Model.UNSPECIFIED,
}


def get_today_dir() -> Path:
    """è·å–ä»Šå¤©çš„å›¾ç‰‡ç›®å½•ï¼šå¹´æœˆ/æ—¥æœŸ"""
    now = datetime.now()
    year_month = now.strftime("%Y%m")
    date = now.strftime("%Y%m%d")
    dir_path = IMAGES_BASE_DIR / year_month / date
    dir_path.mkdir(parents=True, exist_ok=True)
    return dir_path


def generate_filename() -> str:
    """ç”Ÿæˆæ–‡ä»¶åï¼šå¹´æœˆæ—¥æ—¶åˆ†ç§’_éšæœºæ•°"""
    timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
    random_suffix = secrets.token_hex(4)
    return f"{timestamp}_{random_suffix}"


def save_conversation(conversation_id: str, metadata: dict):
    """ä¿å­˜å¯¹è¯å†å²"""
    file_path = CONVERSATIONS_DIR / f"{conversation_id}.json"
    with open(file_path, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, ensure_ascii=False, indent=2)
    debug_log(f"å¯¹è¯å·²ä¿å­˜: {conversation_id}", "CHAT")


def load_conversation(conversation_id: str) -> Optional[dict]:
    """åŠ è½½å¯¹è¯å†å²"""
    file_path = CONVERSATIONS_DIR / f"{conversation_id}.json"
    if file_path.exists():
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    return None


@app.get("/", response_class=HTMLResponse)
async def root():
    """è¿”å›å‰ç«¯é¡µé¢"""
    index_file = STATIC_DIR / "index.html"
    if index_file.exists():
        with open(index_file, "r", encoding="utf-8") as f:
            return f.read()
    else:
        return """
        <html>
            <head><title>Gemini Chat</title></head>
            <body style="font-family: Arial; text-align: center; padding: 50px;">
                <h1>âš ï¸ å‰ç«¯é¡µé¢æœªæ‰¾åˆ°</h1>
                <p>è¯·åœ¨ <code>static/index.html</code> åˆ›å»ºå‰ç«¯é¡µé¢</p>
                <p>æˆ–è®¿é—® <a href="/docs">API æ–‡æ¡£</a></p>
            </body>
        </html>
        """


@app.post("/v1/chat/completions")
async def chat_completions(request: ChatRequest, req: Request):
    """
    OpenAI å…¼å®¹æ¥å£

    æ”¯æŒï¼š
    1. çº¯æ–‡æœ¬å¯¹è¯
    2. å¸¦æ–‡ä»¶çš„å¯¹è¯ï¼ˆfiles å‚æ•°ä¼ é€’æ–‡ä»¶è·¯å¾„ï¼‰
    3. å¯¹è¯å†å²ï¼ˆconversation_idï¼‰
    """
    try:
        user_message = request.messages[-1].content
        model = MODEL_MAP.get(request.model, Model.UNSPECIFIED)
        conversation_id = request.conversation_id
        files = request.files

        debug_log("=" * 60, "REQUEST")
        debug_log(f"æ¨¡å‹: {request.model}", "REQUEST")
        debug_log(f"å¯¹è¯ID: {conversation_id or 'æ–°å¯¹è¯'}", "REQUEST")
        debug_log(f"æ¶ˆæ¯: {user_message[:100]}{'...' if len(user_message) > 100 else ''}", "REQUEST")
        if files:
            debug_log(f"åŒ…å«æ–‡ä»¶: {len(files)} ä¸ª", "FILE")
        debug_log("=" * 60, "REQUEST")

        # è·å–æˆ–åˆ›å»ºå¯¹è¯
        chat = None
        if conversation_id:
            if conversation_id in active_chats:
                chat = active_chats[conversation_id]
                debug_log("ä½¿ç”¨å†…å­˜ä¸­çš„å¯¹è¯", "CHAT")
            else:
                metadata = load_conversation(conversation_id)
                if metadata:
                    chat = gemini_client.start_chat(metadata=metadata, model=model)
                    active_chats[conversation_id] = chat
                    debug_log("ä»æ–‡ä»¶æ¢å¤å¯¹è¯", "CHAT")

        if chat is None:
            if not conversation_id:
                conversation_id = str(uuid.uuid4())

            chat = gemini_client.start_chat(model=model)
            active_chats[conversation_id] = chat
            debug_log(f"åˆå§‹åŒ–æ–°ä¼šè¯: {conversation_id}", "CHAT")

        # å‘é€æ¶ˆæ¯ï¼ˆå®˜æ–¹ API è‡ªåŠ¨å¤„ç†æ–‡ä»¶ï¼‰
        debug_log("æ­£åœ¨å‘é€æ¶ˆæ¯åˆ° Gemini...", "REQUEST")
        start_time = time.time()

        if files:
            response = await chat.send_message(user_message, files=files)
        else:
            response = await chat.send_message(user_message)

        elapsed_time = time.time() - start_time
        debug_log(f"æ”¶åˆ°å“åº” (è€—æ—¶: {elapsed_time:.2f}s)", "RESPONSE")

        content = response.text or ""
        debug_log(f"å“åº”é•¿åº¦: {len(content)} å­—ç¬¦", "RESPONSE")

        # ä¿å­˜å¯¹è¯å†å²
        save_conversation(conversation_id, chat.metadata)

        # å¤„ç† AI ç”Ÿæˆçš„å›¾ç‰‡ï¼ˆä½¿ç”¨å®˜æ–¹ API çš„ save æ–¹æ³•ï¼‰
        if response.images:
            debug_log(f"å“åº”åŒ…å« {len(response.images)} å¼ å›¾ç‰‡", "IMAGE")
            base_url = f"{req.url.scheme}://{req.headers.get('host', req.client.host)}"
            content += "\n\n**ç”Ÿæˆçš„å›¾ç‰‡ï¼š**\n"

            today_dir = get_today_dir()

            for idx, img in enumerate(response.images, 1):
                filename = generate_filename()
                # ä½¿ç”¨å®˜æ–¹ API çš„ save æ–¹æ³•
                success = await img.save(
                    path=str(today_dir),
                    filename=f"{filename}.png"
                )

                if success:
                    # æŸ¥æ‰¾ä¿å­˜çš„æ–‡ä»¶
                    saved_file = today_dir / f"{filename}.png"
                    if saved_file.exists():
                        relative_path = saved_file.relative_to(IMAGES_BASE_DIR)
                        image_url = f"{base_url}/images/{relative_path.as_posix()}"
                        content += f"\n![Image {idx}]({image_url})"
                        debug_log(f"å›¾ç‰‡ #{idx} å·²ä¿å­˜", "SUCCESS")

        return {
            "id": f"chatcmpl-{uuid.uuid4()}",
            "object": "chat.completion",
            "created": int(time.time()),
            "model": request.model,
            "conversation_id": conversation_id,
            "choices": [{
                "index": 0,
                "message": {
                    "role": "assistant",
                    "content": content
                },
                "finish_reason": "stop"
            }]
        }

    except Exception as e:
        debug_log(f"è¯·æ±‚å¤±è´¥: {type(e).__name__}: {e}", "ERROR")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/upload")
async def upload_files(files: List[UploadFile] = File(...)):
    """
    æ–‡ä»¶ä¸Šä¼ æ¥å£
    è¿”å›ä¸Šä¼ æ–‡ä»¶çš„è·¯å¾„ï¼Œä¾›åç»­èŠå¤©ä½¿ç”¨
    """
    try:
        debug_log(f"æ”¶åˆ°æ–‡ä»¶ä¸Šä¼ : {len(files)} ä¸ª", "FILE")

        uploaded_paths = []
        for file in files:
            file_path = UPLOADS_DIR / f"{generate_filename()}_{file.filename}"
            content = await file.read()

            with open(file_path, 'wb') as f:
                f.write(content)

            uploaded_paths.append(str(file_path))
            debug_log(f"æ–‡ä»¶å·²ä¿å­˜: {file.filename}", "SUCCESS")

        return {
            "success": True,
            "files": uploaded_paths,
            "count": len(uploaded_paths)
        }

    except Exception as e:
        debug_log(f"ä¸Šä¼ å¤±è´¥: {e}", "ERROR")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/conversations")
async def list_conversations():
    """åˆ—å‡ºæ‰€æœ‰å¯¹è¯"""
    conversations = []
    for file_path in CONVERSATIONS_DIR.glob("*.json"):
        stat = file_path.stat()
        conversations.append({
            "conversation_id": file_path.stem,

            "modified": datetime.fromtimestamp(stat.st_mtime).isoformat(),
            "size_kb": round(stat.st_size / 1024, 2)
        })
    conversations.sort(key=lambda x: x['modified'], reverse=True)
    return {"total": len(conversations), "conversations": conversations}


@app.get("/conversations/{conversation_id}")
async def get_conversation(conversation_id: str):
    """è·å–å¯¹è¯è¯¦æƒ…"""
    metadata = load_conversation(conversation_id)
    if not metadata:
        raise HTTPException(status_code=404, detail="Conversation not found")
    return {"conversation_id": conversation_id, "metadata": metadata}


@app.delete("/conversations/{conversation_id}")
async def delete_conversation(conversation_id: str):
    """åˆ é™¤å¯¹è¯"""
    if conversation_id in active_chats:
        del active_chats[conversation_id]

    file_path = CONVERSATIONS_DIR / f"{conversation_id}.json"
    if file_path.exists():
        file_path.unlink()
        return {"message": "Conversation deleted"}

    raise HTTPException(status_code=404, detail="Conversation not found")


@app.get("/images/{year_month}/{date}/{filename}")
async def get_image(year_month: str, date: str, filename: str):
    """è¿”å›å›¾ç‰‡"""
    file_path = IMAGES_BASE_DIR / year_month / date / filename
    if not file_path.exists() or not file_path.is_file():
        raise HTTPException(status_code=404, detail="Image not found")
    return FileResponse(str(file_path.absolute()), media_type="image/png")


@app.get("/v1/models")
async def list_models():
    """åˆ—å‡ºæ¨¡å‹"""
    return {
        "object": "list",
        "data": [
            {"id": name, "object": "model", "owned_by": "google"}
            for name in MODEL_MAP.keys()
        ]
    }


@app.get("/health")
async def health():
    """å¥åº·æ£€æŸ¥"""
    images = list(IMAGES_BASE_DIR.rglob("*.jpg"))
    images.extend(IMAGES_BASE_DIR.rglob("*.png"))
    total_size = sum(f.stat().st_size for f in images if f.is_file())
    conversations = list(CONVERSATIONS_DIR.glob("*.json"))
    uploads = list(UPLOADS_DIR.glob("*"))

    return {
        "status": "ok",
        "storage": {
            "images_directory": str(IMAGES_BASE_DIR.absolute()),
            "total_images": len(images),
            "total_size_mb": round(total_size / 1024 / 1024, 2)
        },
        "conversations": {
            "directory": str(CONVERSATIONS_DIR.absolute()),
            "total": len(conversations),
            "active_in_memory": len(active_chats)
        },
        "uploads": {
            "directory": str(UPLOADS_DIR.absolute()),
            "total_files": len(uploads)
        }
    }


if __name__ == "__main__":
    import uvicorn

    debug_log("=" * 60, "INFO")
    debug_log("ğŸš€ å¯åŠ¨ Gemini Chat æœåŠ¡å™¨", "INFO")
    debug_log(f"ğŸ“ åœ°å€: http://{HOST}:{PORT}", "INFO")
    debug_log(f"ğŸ“š API æ–‡æ¡£: http://{HOST}:{PORT}/docs", "INFO")
    debug_log(f"ğŸ¨ å‰ç«¯é¡µé¢: http://{HOST}:{PORT}/", "INFO")
    debug_log("=" * 60, "INFO")

    uvicorn.run("server:app", host=HOST, port=PORT, reload=True)
